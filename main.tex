\documentclass[11pt, a4paper]{article} %\documentclass[11pt, a4paper, twoside, openright]{article} %draft

\usepackage{graphicx,color}
\usepackage{amssymb, amsmath, array}
\usepackage{hyperref}
\usepackage{newpxtext, newpxmath}
\usepackage{minted}
\usemintedstyle{friendly}

\begin{document}

\onecolumn

\input{cover}


\thispagestyle{empty}

\newpage

\tableofcontents{\protect\thispagestyle{empty}

\clearpage

\section{Introduction}

With the Internet cemented as a principal keystone in communication, and ever
increasing activity taking place digitially, the importance of secure
communication and Cryptography has never been greater. Thankfully, after
50 years of Public Key Cryptography
\cite{hellman_overview_1978},
we have good theoretical systems to provide these guarantees.

Most of these systems rely on modular arithmetic with large numbers,
such as RSA or Elliptic Curve Cryptography
\cite{rivest_method_1978, miller_use_1986}
.
Working with such numbers is not natively supported by hardware,
requiring a "Big Number" software library to provide this functionality.

Unfortunately, even though Public Key Cryptosystems have been heavily
scrutinized \textit{in theory}, in practice many vulnerabilities arise
in software implementations of these systems.

One particularly pernicious class of vulnerability are
\textbf{timing attacks}
\cite{kocher_cryptanalysis_1995}, where an implementation leaks information
about secret values through its execution time or cache usage, among
many side-channels.

Libraries for Big Numbers that are not designed with Cryptography in mind
are pervasively vulnerable to this class of attack.

In particular, Go \cite{the_go_authors_go_nodate} provides a general purpose
Big Number type, \texttt{big.Int}, which suffers from these vulnerabilities,
as we detail later in this report. Unfortunately, this library
gets used for Cryptography
\cite{ford_proposal_2017}, including inside of Go's own standard library,
in \texttt{go/crypto}.

We've addressed this issue by creating a library
\cite{meier_cronokirbysafenum_2021}
designed to work with Big Numbers in the context of Public Key Cryptography.
Our library provides the necessary operations for implementing these systems,
all while avoiding the leakage of secret information.
To demonstrate its utility, we've modified Go's \texttt{go/crypto}
package, replacing the use of \texttt{big.Int} in the DSA and RSA
systems.

\section{Background}

In this section, we explain how Big Numbers are used in Public Key
Cryptography, what timing attacks are, and how they affect our threat
model, as well as what kind of side-channels are present in Go's
\texttt{big.Int} type.

\subsection{Big Numbers in Cryptography}

As mentioned previously, most Public Key Cryptosystems rely on
modular arithmetic.

In RSA \cite{rivest_method_1978}, for example, a public key $(e, N)$ consists of modulus
$N \in \mathbb{N}$, usually 2048 bits long, and an exponent taken
modulo $\varphi(N)$.
To encrypt a message $m \in \mathbb{Z}/N\mathbb{Z}$, we calculate

$$
c := m^e \mod N
$$

The typical word size on computers is now 64 bits. Because of this,
to do arithmetic modulo $N$, we need a Big Number library to work
with these large numbers, as well as to provide optimized implementations
of opereaitons like modular exponentiation, which aren't natively supported.

DSA
\cite{technology_digital_1994} also relies on modular arithmetic,
this time using a large prime $p$ of around 2048 bits, and working
in the multiplicative group $(\mathbb{Z}/p\mathbb{Z})^*$.

Elliptic Curve Cryptography
\cite{miller_use_1986} relies on complex formulas for adding points
on an elliptic curve, built over a finite field $K$. This field
is usually either a prime field $\mathbb{Z}/p\mathbb{Z}$, in which case arithmetic
modulo $p$ is used, or a
binary extension field $\text{GF}(2^n)$, in which case
binary arithmetic in combination with polynomial addition and multiplication
are used.

For prime fields, a Big Number library is once again necessary, because
the size of the prime is greater than 200 bits.

In summary, large modular arithmetic is a cornerstone of Public Key
cryptosystems, requiring Big Numbers in some form.

\subsubsection{Implementing Big Numbers}

Describe different strategies in place for providing numbers for
Cryptography.

\subsubsection{Big Numbers in \texttt{go/crypto}}

Go \cite{the_go_authors_go_nodate} provides implementations of numerous
cryptographic algorithms as part of its standard library,
including the aforementioned Public Key systems, in the
\texttt{go/crypto} package.

Unfortunately \cite{ford_proposal_2017}, the general purpose
\texttt{big.Int} type gets used in this package for Cryptography,
despite its potential vulnerability to timing attacks.

For DSA \cite{technology_digital_1994}, Go uses \texttt{big.Int}
for all operations, including key generation, signing, and verification.

For RSA \cite{rivest_method_1978}, Go uses \texttt{big.Int}
for all operations, and fixes this type as part of the API for
this package. Key generation, encryption, decryption, signing,
and verification all use \texttt{big.Int}.

For ECC \cite{miller_use_1986}, Go defines a general interface
for Elliptic Curves, requiring operations like point addition,
scalar multiplication, etc. All of these are defined in terms
of \texttt{big.Int}. Some of the curves have specialized
implementations of their prime field, only converting from
\texttt{big.Int} to satisfy the interface curves. The remaining curves
directly make use \texttt{big.Int} for their field arithmetic.

\subsection{Timing Attacks}

A side-channel
\cite{kelsey_side_1998}
leaks secret information about a program not directly,
but indirectly, through the observable properties of its execution.
For example, timing side-channels use the execution time of a program
to infer properties of the secret data it processes. 
A timing attack is the use of a timing side-channel to break the security
of some program or cryptographic protocol.

If a program takes a different number of steps based on the value of some
secret, then this constitutes an obvious timing side-channel.
For example, if a naive program for comparing inputs with a secret password
stops as soon as a mismatch is found, then the algorithm itself has
a timing side-channel. This side-channel can be exploited, to allow
the secret password to be guessed byte by byte.

Not all timing side-channels are this simple, however. Algorithms
that take the same number of steps regardless of the value of secret
data can still having timing side-channels because of how the underlying
hardware executing the program works. For example, a processor may
execute an operation faster for some inputs, or the presence of a cache
could be used to infer what addresses are being accessed. These
microarchitectural timing side-channels are also of concern.
See \cite{ge_survey_2018} for a survey of these vulnerabilities.

\subsubsection{Actual Attacks}

The presence of a side-channel does not directly lead to vulnerabilities.
As early as 1995, Paul Kocher
demonstrated the potential for timing attacks against cryptographic
algorithms \cite{kocher_cryptanalysis_1995, kocher_timing_1996}.
These specific attacks rely on algorithms that perform a varying number of
operations based on secret data. 

One common objection to timing attacks more generally is that they
while a timing side-channel is catastrophic in theory, in practice
this channel is too noisy to exploit. Unfortunately, through gathering
many samples, it's possible to exploit these attacks even across
a network \cite{brumley_remote_2005, brumley_remote_2011}.

The use of caches as a potential side-channel was
identified early on as well \cite{page_theoretical_2002}.
The idea is that accessing data that is not present in the cache
takes longer than accessing data inside of the cache. If what data
is being accessed depends on a secret value, the observed execution
time will thus also depend on this secret value. If an attacker is located
on the same machine they can place data into the cache as well, and probe
the cache themselves, to learn fine-grained information about the
program's access patterns. While seemingly far-fetched, this is easy
to achieve now that so many applications are run on cloud computing.

A wide variety of attacks involving caches have been mounted
against various cryptosystems
\cite{
  bernstein_cache-timing_2005,
  yarom_cachebleed_2017,
  cabrera_aldaya_cache-timing_2019}
, making accessing data based on secret
values fraught with peril.

\subsubsection{Our Threat-Model}
\label{threat_model}

Although the variety of potential timing side-channels is quite daunting,
we can distill them into a simple, albeit pessimistic set of rules:

\begin{enumerate}
  \item Any loop leaks the number of iterations taken.
  \item Any memory access leaks the address accessed.
  \begin{enumerate}
    \item As a consequence, accessing an array leaks the index accessed.
  \end{enumerate}
  \item Any conditional statement leaks which branch was taken.
\end{enumerate}

Rule 1 is justified by theoretical concerns, since a longer loop
requires more operations. In practice, it's difficult to observe
the iterations of each loop in a program from an overall timing signal,
making this a pessimistic rule.

Rule 2 is justified by various cache based side-channels and attacks
\cite{
  bernstein_cache-timing_2005,
  yarom_cachebleed_2017,
  cabrera_aldaya_cache-timing_2019}.
Since caches only load information an entire line at a time, it might
seem that our rule is too pessimistic, and that only which cache line
was accessed should be kept secret \cite{brickell_technologies_2011}.
Unfortunately, the potential for attacks on much finer grained
level has been demonstrated
\cite{
  bernstein_word_2013,
  osvik_cache_2006,
  yarom_cachebleed_2017}.
Because of these concerns, we take a pessimistic position, and assume
that accessing an array leaks the exact index accessed.


Rule 3 is justified in two ways. First, if different branches of a conditional
statement execute a different number of operations, this leaks information
about which branch was taken in a fundamental way. Second, even if both
branches execute identitical operations, the CPU's branch predictor
can be exploited, leaking information about which branch was taken
\cite{
  aciicmez_predicting_2006,
  aciicmez_power_2007,
  evtyushkin_jump_2016}.

In addition to these rules, we assume that addition, multiplication,
logical operations, and shifts, as implemented in hardware,
are constant-time in their inputs.
This is the case on most processors, one notable exception being
microprocessors
\cite{pornin_bearssl_nodate}. For the platforms which Go,
and thus our library, targets,
this assumption is reasonable.

\subsection{Vulnerabilities in \texttt{big.Int}}

Go provides a general purpose type for Big Numbers: \texttt{big.Int}.
This implementation is concerned with being broadly applicable,
and well-optimized. It does not focus on security, or on hardening
itself against timing side-channels.

Unfortunately, its broad applicability makes it useful for cryptography,
and it gets used throughout Go's standard cryptography library,
as we've seen previously.

In this section, we look at some of the important implementation aspects
of \texttt{big.Int}, and how they might be potentially vulnerable
according to our threat model.

\subsubsection{Padding}

The \texttt{big.Int} type always normalizes numbers internally,
removing any leading zero limbs. Even if you initialize a number
using bytes zero-padded to a certain length, the resulting value
will immediately chop off these zeros. These extra zeros don't
change the value of a number. By discarding them, operations on
this number will have fewer limbs to process, and will be faster.

Unfortunatelly, this means that \texttt{big.Int} leaks information
about the padding of numbers pervasively. Since every operation on
a number takes more time the more limbs the number uses,
the removal of padding leaks the true sizes of numbers
at every operation.
Leaking this padding has been exploited
in OpenSSL \cite{merget_raccoon_2019}, and might potentially
be a vulnerability in Go's cryptography library, because of \texttt{big.Int}.

\subsubsection{Leaky Algorithms}

Because \texttt{big.Int} is not written with Cryptography in mind,
its methods violate the rules set in
\ref{threat_model}. Many methods take a different number of iterations
based on their values, branch conditionally on values, and
access memory depending on values. Because \texttt{big.Int}
is designed for general purpose use, this problem should only get worse
as the library is further developed and optimized.

Ultimately, the problem is not the existence of \texttt{big.Int},
but it's use in Go's cryptography library, and in the broader ecosystem.

\subsubsection{Mitigations}

Although \texttt{big.Int} gets used in Go's cryptography library,
the authors are aware of its shortcomings, and have implemented
several mitigations to try and make its timing side-channels harder to
exploit.

One of the most important ones is a mitigation
for RSA: blinding \cite{kocher_timing_1996}. The decrypt a ciphertext
$c = m^e \mod N$, we normally calculate:

$$
c^d \mod N
$$

with $d$ our private key, and $(e, N)$ our public key.
When exponentiation is not implemented in a constant-time way, like
with \texttt{big.Int}, this process can leak information about $m$.
If an adversary can choose $c$, then this can leak information about
$d$ as well.

To mitigate this, instead of decrypting $c$ directly,
we first generate a random integer
$r \in [0, N - 1]$, and make sure
it has an inverse $r^{-1}$ mod $N$. Then we decrypt $r^e \cdot c$.
This gives us the value $r \cdot m$, and we can recover
$m$ by multiplying by $r^{-1}$.

While this does effectively mitigate the simplest attacks
against exponentiation, a very leaky operation, the other operations
involving these values are still left unprotected, and may
have exploitable leakages in more subtle ways. We also have
the unaddressed issue of padding, which has lead to attacks
in OpenSSL \cite{merget_raccoon_2019}.

\section{Implementation}

We've implemented a library, called
\texttt{safenum} \cite{meier_cronokirbysafenum_2021}, intended to provide
a replacement for \texttt{big.Int}, suitable for use in Cryptography.
In order to demonstrate its utility, we've replaced some
of \texttt{go/crypto}'s usage of \texttt{big.Int} with our own library,
in a separate repository
\cite{meier_cronokirbyctcrypto_2021}.

In this section, we go over the design and implementation of our
library.

\subsection{The \texttt{safenum} library}

Safenum defines a \texttt{Nat} type, which is intended to
replace \texttt{big.Int}. This type represents arbitrary
numbers in $\mathbb{N}$. Unlike \texttt{big.Int}, we do not handle
negative numbers. Handling a sign bit in constant-time is exceedingly
tricky. Thankfully, we haven't found this limitation to be restrictive
when replacing \texttt{big.Int} in Go's cryptography library.

We provide operations for addition and multiplication of \texttt{Nats},
all other operations are for modular arithmetic. For modular arithmetic,
we provide numerous operations, including modular addition, subtraction,
multiplication, exponentiation, inversion, reduction, and taking
square roots modulo prime numbers. We also provide the usual operations
for serializing to and from bytes.

We try and structure the API in a similar way to \texttt{big.Int},
where an operation is performed on a buffer \texttt{Nat}, which
can receive the result. For example, this is the signature for
modular addition:

\begin{minted}{Go}
func (z *Nat) ModAdd(x *Nat, y *Nat, m *Modulus) *Nat
\end{minted}

This calculates $z \leftarrow x + y \mod m$, returning $z$. The advantage
of structuring the API this way, instead of simply returning a new
value, is that we can reuse the memory of $z$ for the result.

We go one step further, in fact, and use the memory of the buffer
\texttt{Nat} for all scratch space needed inside of an operation.
Structuring our operations this way allows us to limit unnecessary waste
of allocation.

\subsubsection{Handling Size}

Unlike \texttt{big.Int}, a \texttt{Nat} doesn't truncate its limbs
to remove any zero padding. Because of this, we distinguish
between the \emph{true size} of a number, which is how many significant
bits or limbs it actually has, and the \emph{announced size}
of a number, which is how many limbs are actually used to store
that number. The announced size is allowed to be leaked, while the
true size should be kept secret. The true size is always
at most the announced size

Because of this, we need to ensure that there's always a clear
announced size to use for the results that we produced. For modular
operations, we have an obvious choice: the size of the modulus.
When doing a modular operation, the result will always receive
the same announced size as the modulus does.

For example, when doing modular addition:

\begin{minted}{Go}
func (z *Nat) ModAdd(x *Nat, y *Nat, m *Modulus) *Nat
\end{minted}

our result \texttt{z} will have the same announced size as \texttt{m}.
After modular addition, we have that $z \in [0, m - 1]$ by definition.
Because of this, leaking the fact that the true size of $z$
is at most that of $m$ leaks no information about what value $z$
actually has, beyond what's knowable just by inspecting the call
graph in the source code of a program.

When serializing a \texttt{Nat}, we respect its announced size,
and produce zeros for padding as necessary. This is done without
any special handling, because we already store padded limbs anyways.

Similarly, when deserializing a \texttt{Nat} from bytes,
we respect any padding, unlike \texttt{big.Int}. For example,
if 32 big endian bytes are deserialized, we will end up
with a \texttt{Nat} with an announced size of 256 bits, regardless
of the value of those bytes.

This leaves us with non-modular addition and multiplication of numbers.
One approach is to use the maximum possible resulting size for our
result's announced length. For example, if we multiply
numbers $x_1$ and $x_2$, of announced size $b_1$ and $b_2$, then
our result will need a size of at most $b_1 + b_2$.
In situations where we know that our result will be smaller,
this size explosion can be undesirable.

Because of this, we opt towards letting users specify exactly how many
resulting bits they need in the output. For example,
multiplication has the following signature:

\begin{minted}{Go}
func (z *Nat) Mul(x *Nat, y *Nat, cap uint) *Nat
\end{minted}

Here \texttt{cap} is the number of bits that the result should have.
We use this to determine the result's announced length. Any output
beyond that capacity will simply be discarded.

In summary, the announced size of a \texttt{Nat} is always
clear based on how it's produced, and results from deserializing
a value, from using the same size as a modulus, or from manually
deciding on an output size.

\subsubsection{Moduli}

In our library, we've decided to make a separate type for representing
the moduli used in modular arithmetic: \texttt{Modulus}. There are several
reasons for doing this.

First, various operations in modular arithmetic require different properties
of the modulus which can be pre-computed. For example, montgomery multiplication
requires us to know $m^{-1} \mod 2^b$, with $b$ the number of bits in a limb,
and $m$ our modulus. By using a separate type for moduli, we can
precompute these values.

Second, the true size of a modulus is considered to be leakable.
As a consequence, moduli are stored \emph{without} padding.
This is desirable because modular reduction needs access to the most
significant bits of a modulus, and fetching this information without
leaking padding is exceedingly difficult. Furthermore,
by storing moduli without padding, the announced size of numbers produced
through modular operations is as tight as possible, which speeds
up operation.

This assumption is safe in cryptography. Moduli are often public,
like with the public modulus $N$ in RSA. In this case, leaking
the true size is fine, since even the exact value is known. There
are some cases where a secret modulus is necessary. For example,
when generating an RSA key, we use the factorization $N = pq$ of the modulus,
and calculate our private key modulo $\varphi(N) := (p - 1)(q - 1)$:

$$
d := e^{-1} \mod \varphi(N)
$$

Leaking the value of $\varphi(N)$ would be catastrophic. On the other hand,
it's clear that the true size of $\varphi(N)$ is approximately
that of $N$, which is known. In this case, leaking the true size of
$\varphi(N)$ is fine.

Using a separate modulus type is necessary to have this
weaker constraint on its announced size.

\subsection{Constant-Time Operations}

Describe some basic techniques for constant-time operation.

\subsection{Algorithm Choices}

Describe the algorithm choices we've used for different things.

\subsection{Implementation Techniques}

\subsubsection{Saturated or Unsatured Limbs}

\subsubsection{Redundant Reductions}

\section{Results}

Describe what results we've managed to perform.

\subsection{Comparison with \texttt{big.Int}}

Describe the final performance results we've managed to achieve.

\subsection{Comparison with \texttt{go/crypto}}

Describe the benchmarks on actual code.

\section{Further Work}

\subsection{Upstreaming to \texttt{go/crypto}}

Describe our work in providing a patch for RSA, and what results we've
managed to achieve.

\section{Conclusion}

Summarize the things we put in the introduction.

\section*{Acknowledgements}
\addcontentsline{toc}{section}{Acknowledgements}

\bibliographystyle{plainurl}
\bibliography{references}
\end{document}
